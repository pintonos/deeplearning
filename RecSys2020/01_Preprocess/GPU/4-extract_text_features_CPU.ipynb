{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020, NVIDIA CORPORATION.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm \n",
    "import glob\n",
    "import gc\n",
    "import os.path\n",
    "\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_memory( df ):\n",
    "    features = df.columns\n",
    "    for i in range( df.shape[1] ):\n",
    "        if df.dtypes[i] == 'uint8':\n",
    "            df[features[i]] = df[features[i]].astype( np.int8 )\n",
    "            gc.collect()\n",
    "        elif df.dtypes[i] == 'bool':\n",
    "            df[features[i]] = df[features[i]].astype( np.int8 )\n",
    "            gc.collect()\n",
    "        elif df.dtypes[i] == 'uint32':\n",
    "            df[features[i]] = df[features[i]].astype( np.int32 )\n",
    "            gc.collect()\n",
    "        elif df.dtypes[i] == 'int64':\n",
    "            df[features[i]] = df[features[i]].astype( np.int32 )\n",
    "            gc.collect()\n",
    "        elif df.dtypes[i] == 'float64':\n",
    "            df[features[i]] = df[features[i]].astype( np.float32 )\n",
    "            gc.collect()\n",
    "    print( df.dtypes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hash(text, split_text='@', no=0):\n",
    "    text = text.lower()\n",
    "    uhash = ''\n",
    "    text_split = text.split('@')\n",
    "    if len(text_split)>(no+1):\n",
    "        text_split = text_split[no+1].split(' ')\n",
    "        cl_loop = True\n",
    "        uhash += clean_text(text_split[0])\n",
    "        while cl_loop:\n",
    "            if len(text_split)>1:\n",
    "                if text_split[1] in ['_']:\n",
    "                    uhash += clean_text(text_split[1]) + clean_text(text_split[2])\n",
    "                    text_split = text_split[2:]\n",
    "                else:\n",
    "                    cl_loop = False\n",
    "            else:\n",
    "                cl_loop = False\n",
    "    hash_object = hashlib.md5(uhash.encode('utf-8'))\n",
    "    return hash_object.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if len(text)>1:\n",
    "        if text[-1] in ['!', '?', ':', ';', '.', ',']:\n",
    "            return(text[:-1])\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((106254462, 3), (9760684, 3), (9765321, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train = pd.read_parquet( 'train-tweet-1.parquet' )\n",
    "test0 = pd.read_parquet( 'test0-tweet-1.parquet' )\n",
    "test1 = pd.read_parquet( 'test1-tweet-1.parquet' )\n",
    "train.shape, test0.shape, test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.head(100000)\n",
    "#test0 = test0.head(100000)\n",
    "#test1 = test1.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 10min 26s, sys: 8.69 s, total: 10min 35s\nWall time: 10min 34s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "55222970"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "WORDS = {}\n",
    "DF = []\n",
    "for tweet in train['tweet'].unique():\n",
    "    words = tweet.split(' ')\n",
    "    for w in words:\n",
    "        if w not in WORDS:\n",
    "            WORDS[w] = 1\n",
    "        else:\n",
    "            WORDS[w]+= 1\n",
    "gc.collect()\n",
    "\n",
    "for tweet in test0['tweet'].unique():\n",
    "    words = tweet.split(' ')\n",
    "    for w in words:\n",
    "        if w not in WORDS:\n",
    "            WORDS[w] = 1\n",
    "        else:\n",
    "            WORDS[w]+= 1\n",
    "gc.collect()\n",
    "for tweet in test1['tweet'].unique():\n",
    "    words = tweet.split(' ')\n",
    "    for w in words:\n",
    "        if w not in WORDS:\n",
    "            WORDS[w] = 1\n",
    "        else:\n",
    "            WORDS[w]+= 1\n",
    "gc.collect()\n",
    "                \n",
    "len(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1min 4s, sys: 2.37 s, total: 1min 6s\nWall time: 1min 6s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "%%time\n",
    "count=0\n",
    "for w in WORDS:\n",
    "    WORDS[w] = [ WORDS[w], count ]\n",
    "    count+=1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1752, 69905]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "WORDS['marvel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_encode_words( vs ):\n",
    "    li=[]\n",
    "    lf=[]\n",
    "    for v in vs.split(' '):\n",
    "        if v not in ['','[',']','.','!','@','_','#']:\n",
    "            f,i = WORDS[v]\n",
    "            if f<100000:\n",
    "                if f>2:\n",
    "                    li.append( str(i) )\n",
    "                    #li.append( v )\n",
    "                    lf.append( f )\n",
    "    return ' '.join( list((np.array(li)[np.argsort(lf)] )) )    \n",
    "    \n",
    "#freq_encode_words( train['tweet'].values[191019] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_word( x, rw=0 ):\n",
    "    x = x.split(' ')\n",
    "    if rw==0:\n",
    "        if len(x)>=1:\n",
    "            return x[0]\n",
    "    elif rw==1:\n",
    "        if len(x)>=2:\n",
    "            return x[1]\n",
    "    elif rw== -1:\n",
    "        if len(x)>=1:\n",
    "            return x[-1]\n",
    "    elif rw== -2:\n",
    "        if len(x)>=2:\n",
    "            return x[-2]\n",
    "\n",
    "    return '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id                 int32\n",
      "count_ats          int32\n",
      "count_char         int32\n",
      "count_words        int32\n",
      "hash0             object\n",
      "hash1             object\n",
      "tw_uhash          object\n",
      "tw_hash            int32\n",
      "tw_freq_hash       int32\n",
      "tw_first_word     object\n",
      "tw_second_word    object\n",
      "tw_last_word      object\n",
      "tw_llast_word     object\n",
      "tw_len             int32\n",
      "dtype: object\n",
      "CPU times: user 2h 1min 42s, sys: 2min 34s, total: 2h 4min 17s\n",
      "Wall time: 2h 4min 1s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(125780467, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "DF = []\n",
    "train['tweet_nortsign'] = train['tweet'].str.replace('\\[CLS\\] RT @', '')\n",
    "train['count_words']    = train['tweet'].str.count(' ')\n",
    "train['count_char']     = train['tweet'].apply(lambda x: len(x))\n",
    "train['count_ats']      = train['tweet_nortsign'].str.count('@')\n",
    "train['hash0']          = train['tweet_nortsign'].apply(lambda x: extract_hash(x))\n",
    "train['hash1']          = train['tweet_nortsign'].apply(lambda x: extract_hash(x, no=1))\n",
    "train['tw_uhash']       = train['tweet'].apply(lambda x: extract_hash(x, split_text='RT @', no=0))\n",
    "train['tw_hash']        = train['tweet'].apply(lambda x: hash(x)%1000000000 )\n",
    "\n",
    "train['tweet']          = train['tweet'].apply(lambda x: freq_encode_words(x) )\n",
    "train['tw_freq_hash']   = train['tweet'].apply(lambda x: hash(x)%1000000000 )\n",
    "train['tw_first_word']  = train['tweet'].apply(lambda x: ret_word(x,0) )\n",
    "train['tw_second_word'] = train['tweet'].apply(lambda x: ret_word(x,1) )\n",
    "train['tw_last_word']   = train['tweet'].apply(lambda x: ret_word(x,-1) )\n",
    "train['tw_llast_word']  = train['tweet'].apply(lambda x: ret_word(x,-2) )\n",
    "train['tw_len']         = train['tweet'].apply(lambda x: len(x.split(' ')) )\n",
    "\n",
    "DF.append( train[['id','count_ats', 'count_char', 'count_words', 'hash0', 'hash1', 'tw_uhash','tw_hash','tw_freq_hash','tw_first_word','tw_second_word','tw_last_word','tw_llast_word','tw_len']] )\n",
    "del train\n",
    "gc.collect()\n",
    "    \n",
    "\n",
    "test0['tweet_nortsign'] = test0['tweet'].str.replace('\\[CLS\\] RT @', '')\n",
    "test0['count_words']    = test0['tweet'].str.count(' ')\n",
    "test0['count_char']     = test0['tweet'].apply(lambda x: len(x))\n",
    "test0['count_ats']      = test0['tweet_nortsign'].str.count('@')\n",
    "test0['hash0']          = test0['tweet_nortsign'].apply(lambda x: extract_hash(x))\n",
    "test0['hash1']          = test0['tweet_nortsign'].apply(lambda x: extract_hash(x, no=1))\n",
    "test0['tw_uhash']       = test0['tweet'].apply(lambda x: extract_hash(x, split_text='RT @', no=0))\n",
    "test0['tw_hash']        = test0['tweet'].apply(lambda x: hash(x)%1000000000 )\n",
    "\n",
    "test0['tweet']          = test0['tweet'].apply(lambda x: freq_encode_words(x) )\n",
    "test0['tw_freq_hash']   = test0['tweet'].apply(lambda x: hash(x)%1000000000 )\n",
    "test0['tw_first_word']  = test0['tweet'].apply(lambda x: ret_word(x,0) )\n",
    "test0['tw_second_word'] = test0['tweet'].apply(lambda x: ret_word(x,1) )\n",
    "test0['tw_last_word']   = test0['tweet'].apply(lambda x: ret_word(x,-1) )\n",
    "test0['tw_llast_word']  = test0['tweet'].apply(lambda x: ret_word(x,-2) )\n",
    "test0['tw_len']         = test0['tweet'].apply(lambda x: len(x.split(' ')) )\n",
    "\n",
    "DF.append( test0[['id','count_ats', 'count_char', 'count_words', 'hash0', 'hash1', 'tw_uhash','tw_hash','tw_freq_hash','tw_first_word','tw_second_word','tw_last_word','tw_llast_word','tw_len']] )\n",
    "del test0\n",
    "gc.collect()\n",
    "    \n",
    "\n",
    "test1['tweet_nortsign'] = test1['tweet'].str.replace('\\[CLS\\] RT @', '')\n",
    "test1['count_words']    = test1['tweet'].str.count(' ')\n",
    "test1['count_char']     = test1['tweet'].apply(lambda x: len(x))\n",
    "test1['count_ats']      = test1['tweet_nortsign'].str.count('@')\n",
    "test1['hash0']          = test1['tweet_nortsign'].apply(lambda x: extract_hash(x))\n",
    "test1['hash1']          = test1['tweet_nortsign'].apply(lambda x: extract_hash(x, no=1))\n",
    "test1['tw_uhash']       = test1['tweet'].apply(lambda x: extract_hash(x, split_text='RT @', no=0))\n",
    "test1['tw_hash']        = test1['tweet'].apply(lambda x: hash(x)%1000000000 )\n",
    "\n",
    "test1['tweet']          = test1['tweet'].apply(lambda x: freq_encode_words(x) )\n",
    "test1['tw_freq_hash']   = test1['tweet'].apply(lambda x: hash(x)%1000000000 )\n",
    "test1['tw_first_word']  = test1['tweet'].apply(lambda x: ret_word(x,0) )\n",
    "test1['tw_second_word'] = test1['tweet'].apply(lambda x: ret_word(x,1) )\n",
    "test1['tw_last_word']   = test1['tweet'].apply(lambda x: ret_word(x,-1) )\n",
    "test1['tw_llast_word']  = test1['tweet'].apply(lambda x: ret_word(x,-2) )\n",
    "test1['tw_len']         = test1['tweet'].apply(lambda x: len(x.split(' ')) )\n",
    "\n",
    "DF.append( test1[['id','count_ats', 'count_char', 'count_words', 'hash0', 'hash1', 'tw_uhash','tw_hash','tw_freq_hash','tw_first_word','tw_second_word','tw_last_word','tw_llast_word','tw_len']] )\n",
    "del test1\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "DF = pd.concat( DF )\n",
    "gc.collect()\n",
    "\n",
    "save_memory( DF )\n",
    "DF = DF.reset_index( drop=True )\n",
    "gc.collect()\n",
    "#DF.to_parquet( '../input/text-processings-1.parquet' )\n",
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6030294, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   level_0                             index          0  uid\n",
       "0        0  d41d8cd98f00b204e9800998ecf8427e  297988612    0\n",
       "1        1  9b9672de2cbe5ddd7ebd7538945a970a     941760    1\n",
       "2        2  b14a7b8059d9c055954c92674ce60032     801255    2\n",
       "3        3  31cf2397511c7cfce33506bef80e25b7     615980    3\n",
       "4        4  ba9bf05693b9fa202d922dd43a08f281     176764    4"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>index</th>\n      <th>0</th>\n      <th>uid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>297988612</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>9b9672de2cbe5ddd7ebd7538945a970a</td>\n      <td>941760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>b14a7b8059d9c055954c92674ce60032</td>\n      <td>801255</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>31cf2397511c7cfce33506bef80e25b7</td>\n      <td>615980</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>ba9bf05693b9fa202d922dd43a08f281</td>\n      <td>176764</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "uhashes = pd.concat([DF['hash0'], DF['hash1'], DF['tw_uhash']], axis=0)\n",
    "gc.collect()\n",
    "uhashes = uhashes.value_counts()\n",
    "gc.collect()\n",
    "uhashes = uhashes.reset_index().reset_index()\n",
    "gc.collect()\n",
    "uhashes['uid'] = np.arange(0,uhashes.shape[0] )\n",
    "print( uhashes.shape )\n",
    "uhashes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    id  count_ats  count_char  count_words                             hash0  \\\n",
       "0    0          0         196           39  d41d8cd98f00b204e9800998ecf8427e   \n",
       "1    1          0          51            8  d41d8cd98f00b204e9800998ecf8427e   \n",
       "2    2          0          79           10  d41d8cd98f00b204e9800998ecf8427e   \n",
       "3    3          0         186           47  d41d8cd98f00b204e9800998ecf8427e   \n",
       "4    4          0         158           24  d41d8cd98f00b204e9800998ecf8427e   \n",
       "5    5          0          79           11  d41d8cd98f00b204e9800998ecf8427e   \n",
       "6    6          2         134           31  9c0632062672db5b7df952fc6e995f28   \n",
       "7    7          0         126           24  d41d8cd98f00b204e9800998ecf8427e   \n",
       "8    8          0         110           15  d41d8cd98f00b204e9800998ecf8427e   \n",
       "9    9          0          15            2  d41d8cd98f00b204e9800998ecf8427e   \n",
       "10  10          0          98           20  d41d8cd98f00b204e9800998ecf8427e   \n",
       "11  11          1         160           28  e7d696f6e03bab78ac677bc0f27f4732   \n",
       "12  12          0         127           16  d41d8cd98f00b204e9800998ecf8427e   \n",
       "13  13          0         109           15  d41d8cd98f00b204e9800998ecf8427e   \n",
       "14  14          1         197           31  db5dea68000eae1a31fc218a9b84df78   \n",
       "15  15          0          65            6  d41d8cd98f00b204e9800998ecf8427e   \n",
       "16  16          0          71           13  d41d8cd98f00b204e9800998ecf8427e   \n",
       "17  17          0         236           45  d41d8cd98f00b204e9800998ecf8427e   \n",
       "18  18          0         123           22  d41d8cd98f00b204e9800998ecf8427e   \n",
       "19  19          1         259           41  09443b9ca4bf11ed4e93acc772e87616   \n",
       "\n",
       "                               hash1                          tw_uhash  \\\n",
       "0   d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "1   d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "2   d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "3   d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "4   d41d8cd98f00b204e9800998ecf8427e  26bb8a959f2f1b42dd26e5a5dd1bf9f3   \n",
       "5   d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "6   9130545ccd9e058f2f3197c249c85d3b  53bee4efa0d2324d1652e244a1dbd58f   \n",
       "7   d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "8   d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "9   d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "10  d41d8cd98f00b204e9800998ecf8427e  e9fa698016af2792d0fbe5de2cc8f780   \n",
       "11  d41d8cd98f00b204e9800998ecf8427e  365100f78f117333754febf29a347440   \n",
       "12  d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "13  d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "14  d41d8cd98f00b204e9800998ecf8427e  db5dea68000eae1a31fc218a9b84df78   \n",
       "15  d41d8cd98f00b204e9800998ecf8427e  0be79ea49cffad756280050f075fc194   \n",
       "16  d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "17  d41d8cd98f00b204e9800998ecf8427e  d41d8cd98f00b204e9800998ecf8427e   \n",
       "18  d41d8cd98f00b204e9800998ecf8427e  2620dc7726779082d5af48c596391c9b   \n",
       "19  d41d8cd98f00b204e9800998ecf8427e  09443b9ca4bf11ed4e93acc772e87616   \n",
       "\n",
       "      tw_hash  tw_freq_hash tw_first_word tw_second_word tw_last_word  \\\n",
       "0   138108105     210654875            30              4           16   \n",
       "1   825240283      22497716            33             36           38   \n",
       "2    35951641     381879474            40             45           43   \n",
       "3   203087593     928267529            53             79           73   \n",
       "4   639761496     465065934           102            103           90   \n",
       "5   601784522     993787117           114            108          112   \n",
       "6   938905337     624371251           117            119          128   \n",
       "7   595805307     321224596           154            144          142   \n",
       "8   974781930     541664056           164            161          155   \n",
       "9    74993507     817078888           166             -1          166   \n",
       "10  465764522      18638282           167            169          170   \n",
       "11   11359120      50862198           181            188          182   \n",
       "12  807665605     458967190           206            207          202   \n",
       "13  499784304     217549589           217            216          211   \n",
       "14  441646374     693960000           230            229          235   \n",
       "15  762162289     567413183           242             -1          242   \n",
       "16  836543484     442132222           251            252          250   \n",
       "17   85998055     803080273           255            282          275   \n",
       "18  878393786     939247572           289            286          285   \n",
       "19  270104496     139105329           297            304          313   \n",
       "\n",
       "   tw_llast_word  tw_len  tw_hash0  tw_hash1  tw_rt_uhash  \n",
       "0              7      23         0         0            0  \n",
       "1             35       5         0         0            0  \n",
       "2             42       8         0         0            0  \n",
       "3             73      18         0         0            0  \n",
       "4            107      13         0         0         1871  \n",
       "5            110       4         0         0            0  \n",
       "6            128      13       178      2763       194240  \n",
       "7            149       7         0         0            0  \n",
       "8            156       9         0         0            0  \n",
       "9             -1       1         0         0            0  \n",
       "10           168       9         0         0      1113816  \n",
       "11           198      12     13624         0       149744  \n",
       "12           200       8         0         0            0  \n",
       "13           212       6         0         0            0  \n",
       "14           227      11     26072         0        26072  \n",
       "15            -1       1         0         0       543896  \n",
       "16           245       4         0         0            0  \n",
       "17           253      18         0         0            0  \n",
       "18           296       5         0         0         1605  \n",
       "19           317      20    128022         0       128022  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>count_ats</th>\n      <th>count_char</th>\n      <th>count_words</th>\n      <th>hash0</th>\n      <th>hash1</th>\n      <th>tw_uhash</th>\n      <th>tw_hash</th>\n      <th>tw_freq_hash</th>\n      <th>tw_first_word</th>\n      <th>tw_second_word</th>\n      <th>tw_last_word</th>\n      <th>tw_llast_word</th>\n      <th>tw_len</th>\n      <th>tw_hash0</th>\n      <th>tw_hash1</th>\n      <th>tw_rt_uhash</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>196</td>\n      <td>39</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>138108105</td>\n      <td>210654875</td>\n      <td>30</td>\n      <td>4</td>\n      <td>16</td>\n      <td>7</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>51</td>\n      <td>8</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>825240283</td>\n      <td>22497716</td>\n      <td>33</td>\n      <td>36</td>\n      <td>38</td>\n      <td>35</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>79</td>\n      <td>10</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>35951641</td>\n      <td>381879474</td>\n      <td>40</td>\n      <td>45</td>\n      <td>43</td>\n      <td>42</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>186</td>\n      <td>47</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>203087593</td>\n      <td>928267529</td>\n      <td>53</td>\n      <td>79</td>\n      <td>73</td>\n      <td>73</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>158</td>\n      <td>24</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>26bb8a959f2f1b42dd26e5a5dd1bf9f3</td>\n      <td>639761496</td>\n      <td>465065934</td>\n      <td>102</td>\n      <td>103</td>\n      <td>90</td>\n      <td>107</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1871</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0</td>\n      <td>79</td>\n      <td>11</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>601784522</td>\n      <td>993787117</td>\n      <td>114</td>\n      <td>108</td>\n      <td>112</td>\n      <td>110</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>2</td>\n      <td>134</td>\n      <td>31</td>\n      <td>9c0632062672db5b7df952fc6e995f28</td>\n      <td>9130545ccd9e058f2f3197c249c85d3b</td>\n      <td>53bee4efa0d2324d1652e244a1dbd58f</td>\n      <td>938905337</td>\n      <td>624371251</td>\n      <td>117</td>\n      <td>119</td>\n      <td>128</td>\n      <td>128</td>\n      <td>13</td>\n      <td>178</td>\n      <td>2763</td>\n      <td>194240</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0</td>\n      <td>126</td>\n      <td>24</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>595805307</td>\n      <td>321224596</td>\n      <td>154</td>\n      <td>144</td>\n      <td>142</td>\n      <td>149</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0</td>\n      <td>110</td>\n      <td>15</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>974781930</td>\n      <td>541664056</td>\n      <td>164</td>\n      <td>161</td>\n      <td>155</td>\n      <td>156</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0</td>\n      <td>15</td>\n      <td>2</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>74993507</td>\n      <td>817078888</td>\n      <td>166</td>\n      <td>-1</td>\n      <td>166</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0</td>\n      <td>98</td>\n      <td>20</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>e9fa698016af2792d0fbe5de2cc8f780</td>\n      <td>465764522</td>\n      <td>18638282</td>\n      <td>167</td>\n      <td>169</td>\n      <td>170</td>\n      <td>168</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1113816</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>1</td>\n      <td>160</td>\n      <td>28</td>\n      <td>e7d696f6e03bab78ac677bc0f27f4732</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>365100f78f117333754febf29a347440</td>\n      <td>11359120</td>\n      <td>50862198</td>\n      <td>181</td>\n      <td>188</td>\n      <td>182</td>\n      <td>198</td>\n      <td>12</td>\n      <td>13624</td>\n      <td>0</td>\n      <td>149744</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0</td>\n      <td>127</td>\n      <td>16</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>807665605</td>\n      <td>458967190</td>\n      <td>206</td>\n      <td>207</td>\n      <td>202</td>\n      <td>200</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>0</td>\n      <td>109</td>\n      <td>15</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>499784304</td>\n      <td>217549589</td>\n      <td>217</td>\n      <td>216</td>\n      <td>211</td>\n      <td>212</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>1</td>\n      <td>197</td>\n      <td>31</td>\n      <td>db5dea68000eae1a31fc218a9b84df78</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>db5dea68000eae1a31fc218a9b84df78</td>\n      <td>441646374</td>\n      <td>693960000</td>\n      <td>230</td>\n      <td>229</td>\n      <td>235</td>\n      <td>227</td>\n      <td>11</td>\n      <td>26072</td>\n      <td>0</td>\n      <td>26072</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0</td>\n      <td>65</td>\n      <td>6</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>0be79ea49cffad756280050f075fc194</td>\n      <td>762162289</td>\n      <td>567413183</td>\n      <td>242</td>\n      <td>-1</td>\n      <td>242</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>543896</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>0</td>\n      <td>71</td>\n      <td>13</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>836543484</td>\n      <td>442132222</td>\n      <td>251</td>\n      <td>252</td>\n      <td>250</td>\n      <td>245</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0</td>\n      <td>236</td>\n      <td>45</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>85998055</td>\n      <td>803080273</td>\n      <td>255</td>\n      <td>282</td>\n      <td>275</td>\n      <td>253</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>0</td>\n      <td>123</td>\n      <td>22</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>2620dc7726779082d5af48c596391c9b</td>\n      <td>878393786</td>\n      <td>939247572</td>\n      <td>289</td>\n      <td>286</td>\n      <td>285</td>\n      <td>296</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1605</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>1</td>\n      <td>259</td>\n      <td>41</td>\n      <td>09443b9ca4bf11ed4e93acc772e87616</td>\n      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n      <td>09443b9ca4bf11ed4e93acc772e87616</td>\n      <td>270104496</td>\n      <td>139105329</td>\n      <td>297</td>\n      <td>304</td>\n      <td>313</td>\n      <td>317</td>\n      <td>20</td>\n      <td>128022</td>\n      <td>0</td>\n      <td>128022</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "DF['tw_hash0']    = pd.merge( DF[['hash0']]  , uhashes[['index','uid']], left_on='hash0'  , right_on='index', how='left' )['uid']\n",
    "gc.collect()\n",
    "DF['tw_hash1']    = pd.merge( DF[['hash1']]  , uhashes[['index','uid']], left_on='hash1'  , right_on='index', how='left' )['uid']\n",
    "gc.collect()\n",
    "DF['tw_rt_uhash'] = pd.merge( DF[['tw_uhash']], uhashes[['index','uid']], left_on='tw_uhash', right_on='index', how='left' )['uid']\n",
    "gc.collect()\n",
    "DF.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id                 int32\ncount_ats          int32\ncount_char         int32\ncount_words        int32\ntw_hash            int32\ntw_freq_hash       int32\ntw_first_word     object\ntw_second_word    object\ntw_last_word      object\ntw_llast_word     object\ntw_len             int32\ntw_hash0           int32\ntw_hash1           int32\ntw_rt_uhash        int32\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "del DF['hash0'],DF['hash1'],DF['tw_uhash']\n",
    "gc.collect()\n",
    "save_memory( DF )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "DF['tw_hash']        = pd.factorize( DF['tw_hash'] )[0]\n",
    "DF['tw_freq_hash']   = pd.factorize( DF['tw_freq_hash'] )[0]\n",
    "DF['tw_first_word']  = pd.factorize( DF['tw_first_word'] )[0]\n",
    "DF['tw_second_word'] = pd.factorize( DF['tw_second_word'] )[0]\n",
    "DF['tw_last_word']   = pd.factorize( DF['tw_last_word'] )[0]\n",
    "DF['tw_llast_word']  = pd.factorize( DF['tw_llast_word'] )[0]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "DF['tw_hash']        = DF['tw_hash'].astype(np.int32)\n",
    "DF['tw_freq_hash']   = DF['tw_freq_hash'].astype(np.int32)\n",
    "DF['tw_first_word']  = DF['tw_first_word'].astype(np.int32)\n",
    "DF['tw_second_word'] = DF['tw_second_word'].astype(np.int32)\n",
    "DF['tw_last_word']   = DF['tw_last_word'].astype(np.int32)\n",
    "DF['tw_llast_word']  = DF['tw_llast_word'].astype(np.int32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  count_ats  count_char  count_words  tw_hash  tw_freq_hash  \\\n",
       "0   0          0         196           39        0             0   \n",
       "1   1          0          51            8        1             1   \n",
       "2   2          0          79           10        2             2   \n",
       "3   3          0         186           47        3             3   \n",
       "4   4          0         158           24        4             4   \n",
       "5   5          0          79           11        5             5   \n",
       "6   6          2         134           31        6             6   \n",
       "7   7          0         126           24        7             7   \n",
       "8   8          0         110           15        8             8   \n",
       "9   9          0          15            2        9             9   \n",
       "\n",
       "   tw_first_word  tw_second_word  tw_last_word  tw_llast_word  tw_len  \\\n",
       "0              0               0             0              0      23   \n",
       "1              1               1             1              1       5   \n",
       "2              2               2             2              2       8   \n",
       "3              3               3             3              3      18   \n",
       "4              4               4             4              4      13   \n",
       "5              5               5             5              5       4   \n",
       "6              6               6             6              6      13   \n",
       "7              7               7             7              7       7   \n",
       "8              8               8             8              8       9   \n",
       "9              9               9             9              9       1   \n",
       "\n",
       "   tw_hash0  tw_hash1  tw_rt_uhash  \n",
       "0         0         0            0  \n",
       "1         0         0            0  \n",
       "2         0         0            0  \n",
       "3         0         0            0  \n",
       "4         0         0         1871  \n",
       "5         0         0            0  \n",
       "6       178      2763       194240  \n",
       "7         0         0            0  \n",
       "8         0         0            0  \n",
       "9         0         0            0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>count_ats</th>\n      <th>count_char</th>\n      <th>count_words</th>\n      <th>tw_hash</th>\n      <th>tw_freq_hash</th>\n      <th>tw_first_word</th>\n      <th>tw_second_word</th>\n      <th>tw_last_word</th>\n      <th>tw_llast_word</th>\n      <th>tw_len</th>\n      <th>tw_hash0</th>\n      <th>tw_hash1</th>\n      <th>tw_rt_uhash</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>196</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>51</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>79</td>\n      <td>10</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>186</td>\n      <td>47</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>158</td>\n      <td>24</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1871</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0</td>\n      <td>79</td>\n      <td>11</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>2</td>\n      <td>134</td>\n      <td>31</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>13</td>\n      <td>178</td>\n      <td>2763</td>\n      <td>194240</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0</td>\n      <td>126</td>\n      <td>24</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0</td>\n      <td>110</td>\n      <td>15</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0</td>\n      <td>15</td>\n      <td>2</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "DF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "DF.to_parquet( 'text-processings-1.parquet' )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id                int32\n",
       "count_ats         int32\n",
       "count_char        int32\n",
       "count_words       int32\n",
       "tw_hash           int32\n",
       "tw_freq_hash      int32\n",
       "tw_first_word     int32\n",
       "tw_second_word    int32\n",
       "tw_last_word      int32\n",
       "tw_llast_word     int32\n",
       "tw_len            int32\n",
       "tw_hash0          int32\n",
       "tw_hash1          int32\n",
       "tw_rt_uhash       int32\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}